{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Aktienvorhersage-Modell mit Sentiment-Analyse und technischen Indikatoren\n",
        "\n",
        "Dieses Notebook entwickelt ein Klassifikationsmodell, das vorhersagt, ob eine Aktie am nächsten Tag steigt oder fällt.\n",
        "\n",
        "**Datenquellen:**\n",
        "- `stock_tweets.csv`: Tweets zu Aktien mit Zeitstempel\n",
        "- `stock_yfinance_data.csv`: Historische Aktienkurse\n",
        "\n",
        "**Features:**\n",
        "- Sentiment-Analyse mit Transformers\n",
        "- Technische Indikatoren (RSI, Moving Averages)\n",
        "- Zeitliche Aggregation pro Tag und Ticker\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Bibliotheken importieren und Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basis-Bibliotheken für Datenverarbeitung\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Transformer für Sentiment-Analyse\n",
        "from transformers import pipeline\n",
        "\n",
        "print(\"Setup abgeschlossen!\")\n",
        "print(f\"Pandas Version: {pd.__version__}\")\n",
        "print(f\"NumPy Version: {np.__version__}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Daten laden und erste Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tweets laden\n",
        "print(\"Lade Tweet-Daten...\")\n",
        "tweets_df = pd.read_csv('stock_tweets.csv')\n",
        "print(f\"Tweet-Datensatz: {tweets_df.shape[0]} Zeilen, {tweets_df.shape[1]} Spalten\")\n",
        "\n",
        "# Aktienkurse laden\n",
        "print(\"Lade Aktienkurs-Daten...\")\n",
        "stock_df = pd.read_csv('stock_yfinance_data.csv')\n",
        "print(f\"Aktienkurs-Datensatz: {stock_df.shape[0]} Zeilen, {stock_df.shape[1]} Spalten\")\n",
        "\n",
        "# Erste Einblicke\n",
        "print(\"\\n=== Tweet-Daten ===\")\n",
        "print(tweets_df.head())\n",
        "print(\"\\nVerfügbare Aktien in Tweets:\", tweets_df['Stock Name'].unique())\n",
        "\n",
        "print(\"\\n=== Aktienkurs-Daten ===\")\n",
        "print(stock_df.head())\n",
        "print(\"\\nVerfügbare Aktien in Kursdaten:\", stock_df['Stock Name'].unique())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Datenbereinigung und Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datum-Spalten konvertieren\n",
        "print(\"Konvertiere Datumsangaben...\")\n",
        "\n",
        "# Tweets: Datum konvertieren und nur das Datum (ohne Uhrzeit) extrahieren\n",
        "tweets_df['Date'] = pd.to_datetime(tweets_df['Date'], errors='coerce')\n",
        "tweets_df['Date_only'] = tweets_df['Date'].dt.date\n",
        "\n",
        "# Aktienkurse: Datum konvertieren\n",
        "stock_df['Date'] = pd.to_datetime(stock_df['Date'], errors='coerce')\n",
        "stock_df['Date_only'] = stock_df['Date'].dt.date\n",
        "\n",
        "# Fehlende Werte entfernen\n",
        "tweets_df.dropna(subset=['Date', 'Tweet', 'Stock Name'], inplace=True)\n",
        "stock_df.dropna(subset=['Date', 'Close', 'Stock Name'], inplace=True)\n",
        "\n",
        "print(f\"Nach Bereinigung - Tweets: {tweets_df.shape[0]} Zeilen\")\n",
        "print(f\"Nach Bereinigung - Aktienkurse: {stock_df.shape[0]} Zeilen\")\n",
        "\n",
        "# Zeitraum der Daten anzeigen\n",
        "print(f\"\\nTweets Zeitraum: {tweets_df['Date'].min()} bis {tweets_df['Date'].max()}\")\n",
        "print(f\"Aktienkurse Zeitraum: {stock_df['Date'].min()} bis {stock_df['Date'].max()}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Sentiment-Analyse mit Transformer (vereinfacht mit VADER)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Für die Demo verwenden wir VADER (schneller als Transformer)\n",
        "# In der Produktion würden Sie FinBERT oder ähnliche Transformer verwenden\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# VADER Lexikon herunterladen\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "# Sentiment Analyzer initialisieren\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analysiert das Sentiment eines Textes mit VADER\n",
        "    Gibt compound score zurück (-1 bis +1)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        scores = vader.polarity_scores(str(text))\n",
        "        return scores['compound']\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "# Sentiment-Analyse auf Tweets anwenden\n",
        "print(\"Führe Sentiment-Analyse durch...\")\n",
        "tweets_df['sentiment_score'] = tweets_df['Tweet'].apply(analyze_sentiment)\n",
        "\n",
        "print(f\"Sentiment-Analyse abgeschlossen!\")\n",
        "print(f\"Durchschnittlicher Sentiment-Score: {tweets_df['sentiment_score'].mean():.4f}\")\n",
        "print(f\"Sentiment-Score Bereich: {tweets_df['sentiment_score'].min():.4f} bis {tweets_df['sentiment_score'].max():.4f}\")\n",
        "\n",
        "# Verteilung visualisieren\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(tweets_df['sentiment_score'], bins=50, alpha=0.7, edgecolor='black')\n",
        "plt.title('Verteilung der Sentiment-Scores')\n",
        "plt.xlabel('Sentiment-Score (negativ = bearish, positiv = bullish)')\n",
        "plt.ylabel('Anzahl Tweets')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Technische Indikatoren berechnen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technische Indikatoren für jede Aktie berechnen\n",
        "def calculate_technical_indicators(df):\n",
        "    \"\"\"\n",
        "    Berechnet technische Indikatoren für einen DataFrame mit Aktienkursen\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df = df.sort_values('Date').reset_index(drop=True)\n",
        "    \n",
        "    # RSI (Relative Strength Index)\n",
        "    def calculate_rsi(prices, window=14):\n",
        "        delta = prices.diff()\n",
        "        gain = delta.clip(lower=0)\n",
        "        loss = -delta.clip(upper=0)\n",
        "        avg_gain = gain.rolling(window=window, min_periods=window).mean()\n",
        "        avg_loss = loss.rolling(window=window, min_periods=window).mean()\n",
        "        rs = avg_gain / avg_loss\n",
        "        rsi = 100 - (100 / (1 + rs))\n",
        "        return rsi\n",
        "    \n",
        "    # Moving Averages\n",
        "    df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
        "    df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
        "    \n",
        "    # RSI\n",
        "    df['RSI'] = calculate_rsi(df['Close'])\n",
        "    \n",
        "    # Bollinger Bands\n",
        "    df['BB_middle'] = df['Close'].rolling(window=20).mean()\n",
        "    df['BB_std'] = df['Close'].rolling(window=20).std()\n",
        "    df['BB_upper'] = df['BB_middle'] + (df['BB_std'] * 2)\n",
        "    df['BB_lower'] = df['BB_middle'] - (df['BB_std'] * 2)\n",
        "    \n",
        "    # Price relative to Bollinger Bands\n",
        "    df['BB_position'] = (df['Close'] - df['BB_lower']) / (df['BB_upper'] - df['BB_lower'])\n",
        "    \n",
        "    # Volume indicators\n",
        "    df['Volume_MA'] = df['Volume'].rolling(window=20).mean()\n",
        "    df['Volume_ratio'] = df['Volume'] / df['Volume_MA']\n",
        "    \n",
        "    # Price change indicators\n",
        "    df['Price_change'] = df['Close'].pct_change()\n",
        "    df['Price_change_5d'] = df['Close'].pct_change(periods=5)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Technische Indikatoren für jede Aktie berechnen\n",
        "print(\"Berechne technische Indikatoren...\")\n",
        "stock_with_indicators = []\n",
        "\n",
        "for stock in stock_df['Stock Name'].unique():\n",
        "    stock_data = stock_df[stock_df['Stock Name'] == stock].copy()\n",
        "    stock_data_with_indicators = calculate_technical_indicators(stock_data)\n",
        "    stock_with_indicators.append(stock_data_with_indicators)\n",
        "\n",
        "# Alle Aktien wieder zusammenfügen\n",
        "stock_df_enhanced = pd.concat(stock_with_indicators, ignore_index=True)\n",
        "\n",
        "print(f\"Technische Indikatoren berechnet für {stock_df_enhanced['Stock Name'].nunique()} Aktien\")\n",
        "print(f\"Neue Spalten: {[col for col in stock_df_enhanced.columns if col not in stock_df.columns]}\")\n",
        "\n",
        "# Erste Zeilen mit Indikatoren anzeigen\n",
        "print(\"\\nErste Zeilen mit technischen Indikatoren:\")\n",
        "print(stock_df_enhanced[['Date', 'Stock Name', 'Close', 'RSI', 'MA_5', 'MA_20', 'BB_position']].head(10))\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Daten aggregieren und zusammenführen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tweet-Sentiment pro Tag und Aktie aggregieren\n",
        "print(\"Aggregiere Tweet-Sentiment-Daten...\")\n",
        "\n",
        "# Tweets pro Tag und Aktie zusammenfassen\n",
        "tweet_daily = tweets_df.groupby(['Date_only', 'Stock Name']).agg({\n",
        "    'sentiment_score': ['mean', 'std', 'count'],\n",
        "    'Tweet': 'count'\n",
        "}).reset_index()\n",
        "\n",
        "# Spalten umbenennen\n",
        "tweet_daily.columns = ['Date_only', 'Stock Name', 'sentiment_mean', 'sentiment_std', 'sentiment_count', 'tweet_count']\n",
        "\n",
        "# NaN-Werte für Standardabweichung durch 0 ersetzen (wenn nur ein Tweet pro Tag)\n",
        "tweet_daily['sentiment_std'] = tweet_daily['sentiment_std'].fillna(0)\n",
        "\n",
        "print(f\"Tweet-Daten aggregiert: {tweet_daily.shape[0]} Zeilen\")\n",
        "print(\"Erste Zeilen der aggregierten Tweet-Daten:\")\n",
        "print(tweet_daily.head())\n",
        "\n",
        "# Aktienkurs-Daten mit Ziel-Variable erweitern\n",
        "print(\"\\nErstelle Ziel-Variable (nächster Tag steigt/fällt)...\")\n",
        "\n",
        "# Für jede Aktie die Ziel-Variable berechnen\n",
        "stock_with_target = []\n",
        "\n",
        "for stock in stock_df_enhanced['Stock Name'].unique():\n",
        "    stock_data = stock_df_enhanced[stock_df_enhanced['Stock Name'] == stock].copy()\n",
        "    stock_data = stock_data.sort_values('Date').reset_index(drop=True)\n",
        "    \n",
        "    # Ziel-Variable: Steigt der Kurs am nächsten Tag?\n",
        "    stock_data['next_day_close'] = stock_data['Close'].shift(-1)\n",
        "    stock_data['price_up_tomorrow'] = (stock_data['next_day_close'] > stock_data['Close']).astype(int)\n",
        "    \n",
        "    stock_with_target.append(stock_data)\n",
        "\n",
        "stock_df_final = pd.concat(stock_with_target, ignore_index=True)\n",
        "\n",
        "# Letzte Zeile entfernen (kein nächster Tag verfügbar)\n",
        "stock_df_final = stock_df_final.dropna(subset=['next_day_close'])\n",
        "\n",
        "print(f\"Aktienkurs-Daten mit Ziel-Variable: {stock_df_final.shape[0]} Zeilen\")\n",
        "print(f\"Verteilung Ziel-Variable: {stock_df_final['price_up_tomorrow'].value_counts()}\")\n",
        "\n",
        "# Daten zusammenführen\n",
        "print(\"\\nFühre Tweet- und Aktienkurs-Daten zusammen...\")\n",
        "\n",
        "# Merge auf Datum und Aktie\n",
        "final_df = pd.merge(\n",
        "    stock_df_final,\n",
        "    tweet_daily,\n",
        "    on=['Date_only', 'Stock Name'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(f\"Zusammengeführter Datensatz: {final_df.shape[0]} Zeilen, {final_df.shape[1]} Spalten\")\n",
        "\n",
        "# Fehlende Tweet-Daten mit 0 füllen (Tage ohne Tweets)\n",
        "sentiment_cols = ['sentiment_mean', 'sentiment_std', 'sentiment_count', 'tweet_count']\n",
        "final_df[sentiment_cols] = final_df[sentiment_cols].fillna(0)\n",
        "\n",
        "print(f\"Nach Auffüllen fehlender Werte: {final_df.shape[0]} Zeilen\")\n",
        "print(\"\\nErste Zeilen des finalen Datensatzes:\")\n",
        "print(final_df[['Date', 'Stock Name', 'Close', 'RSI', 'sentiment_mean', 'tweet_count', 'price_up_tomorrow']].head())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Machine Learning Modell erstellen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Features für das Modell auswählen\n",
        "print(\"Bereite Daten für Machine Learning vor...\")\n",
        "\n",
        "# Feature-Spalten definieren\n",
        "feature_columns = [\n",
        "    'RSI', 'MA_5', 'MA_20', 'BB_position', 'Volume_ratio',\n",
        "    'Price_change', 'Price_change_5d',\n",
        "    'sentiment_mean', 'sentiment_std', 'tweet_count'\n",
        "]\n",
        "\n",
        "# Nur Zeilen mit allen Features verwenden (keine NaN-Werte)\n",
        "ml_df = final_df.dropna(subset=feature_columns + ['price_up_tomorrow'])\n",
        "\n",
        "print(f\"Datensatz für ML: {ml_df.shape[0]} Zeilen\")\n",
        "print(f\"Features: {feature_columns}\")\n",
        "\n",
        "# Features und Ziel-Variable extrahieren\n",
        "X = ml_df[feature_columns]\n",
        "y = ml_df['price_up_tomorrow']\n",
        "\n",
        "print(f\"Feature-Matrix: {X.shape}\")\n",
        "print(f\"Ziel-Variable: {y.shape}\")\n",
        "print(f\"Klassen-Verteilung: {y.value_counts()}\")\n",
        "\n",
        "# Daten in Training und Test aufteilen (zeitlich sortiert)\n",
        "# Verwende die ersten 80% für Training, die letzten 20% für Test\n",
        "split_idx = int(len(ml_df) * 0.8)\n",
        "\n",
        "X_train = X.iloc[:split_idx]\n",
        "X_test = X.iloc[split_idx:]\n",
        "y_train = y.iloc[:split_idx]\n",
        "y_test = y.iloc[split_idx:]\n",
        "\n",
        "print(f\"\\nTrainingsdaten: {X_train.shape[0]} Zeilen\")\n",
        "print(f\"Testdaten: {X_test.shape[0]} Zeilen\")\n",
        "\n",
        "# Features skalieren\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Random Forest Modell trainieren\n",
        "print(\"\\nTrainiere Random Forest Modell...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'  # Für unbalancierte Klassen\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Vorhersagen auf Testdaten\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "y_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Modell-Performance evaluieren\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModell-Genauigkeit: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nDetaillierter Klassifikationsbericht:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Vorhergesagt')\n",
        "plt.ylabel('Tatsächlich')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Feature-Wichtigkeit und Modell-Analyse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature-Wichtigkeit analysieren\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Feature-Wichtigkeit:\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Feature-Wichtigkeit visualisieren\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Feature-Wichtigkeit im Random Forest Modell')\n",
        "plt.xlabel('Wichtigkeit')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Korrelationsmatrix der Features\n",
        "plt.figure(figsize=(12, 10))\n",
        "correlation_matrix = X.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Korrelationsmatrix der Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Modell-Performance pro Aktie analysieren\n",
        "print(\"\\nModell-Performance pro Aktie:\")\n",
        "test_results = ml_df.iloc[split_idx:].copy()\n",
        "test_results['predicted'] = y_pred\n",
        "test_results['prediction_proba'] = y_pred_proba\n",
        "\n",
        "for stock in test_results['Stock Name'].unique():\n",
        "    stock_data = test_results[test_results['Stock Name'] == stock]\n",
        "    if len(stock_data) > 10:  # Nur Aktien mit genügend Testdaten\n",
        "        stock_accuracy = accuracy_score(stock_data['price_up_tomorrow'], stock_data['predicted'])\n",
        "        print(f\"{stock}: {stock_accuracy:.4f} ({len(stock_data)} Tage)\")\n",
        "\n",
        "# Beispiel-Vorhersagen anzeigen\n",
        "print(\"\\nBeispiel-Vorhersagen (letzte 10 Tage):\")\n",
        "example_predictions = test_results[['Date', 'Stock Name', 'Close', 'sentiment_mean', 'RSI', \n",
        "                                  'price_up_tomorrow', 'predicted', 'prediction_proba']].tail(10)\n",
        "print(example_predictions)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 9. Zusammenfassung und nächste Schritte\n",
        "\n",
        "Das Modell ist jetzt vollständig implementiert! Hier eine Zusammenfassung:\n",
        "\n",
        "### Was das Modell macht:\n",
        "1. **Sentiment-Analyse**: Analysiert Tweets zu Aktien und berechnet tägliche Sentiment-Scores\n",
        "2. **Technische Indikatoren**: Berechnet RSI, Moving Averages, Bollinger Bands, etc.\n",
        "3. **Zeitliche Verknüpfung**: Kombiniert Tweet-Sentiment und Aktienkurse pro Tag und Ticker\n",
        "4. **Klassifikation**: Vorhersage, ob der Aktienkurs am nächsten Tag steigt (1) oder fällt (0)\n",
        "\n",
        "### Verbesserungsmöglichkeiten:\n",
        "1. **Transformer-Modell**: Ersetze VADER durch FinBERT oder ähnliche spezialisierte Modelle\n",
        "2. **Mehr Features**: Weitere technische Indikatoren, Makroökonomische Daten, News-Sentiment\n",
        "3. **Deep Learning**: LSTM oder Transformer für Zeitreihen-Modellierung\n",
        "4. **Ensemble-Methoden**: Kombination mehrerer Modelle für bessere Performance\n",
        "5. **Feature Engineering**: Lag-Features, Rolling Windows, Interaktionen zwischen Features\n",
        "\n",
        "### Wichtige Erkenntnisse:\n",
        "- Die Feature-Wichtigkeit zeigt, welche Indikatoren am stärksten zur Vorhersage beitragen\n",
        "- Das Modell berücksichtigt sowohl technische als auch Sentiment-Faktoren\n",
        "- Die zeitliche Aufteilung verhindert Data Leakage\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
